{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n1mbw0yVXS8f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WoGcS7PXS80"
   },
   "source": [
    "## 1) 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iThdBtGjXS89"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/Train.csv')\n",
    "df_train = df_train.drop(labels=['Id'],axis=1) # 移除 Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qkPR2UCXS9E"
   },
   "source": [
    "## 2) 檢查缺失值\n",
    "使用 numpy 所提供的函式來檢查是否有 NA 缺失值，假設有缺失值使用 dropna() 來移除。使用的時機在於當只有少量的缺失值適用，若遇到有大量缺失值的情況，或是本身的資料量就很少的情況下建議可以透過機器學習的方法補值來預測缺失值。\n",
    "\n",
    "```python\n",
    "# 移除缺失值\n",
    "train=train.dropna()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y9XQTtG_XS9Y"
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5z5AuPBXS9a"
   },
   "outputs": [],
   "source": [
    "# checked missing data\n",
    "print(\"Before data clean(NAN mount):\", len(np.where(np.isnan(df_train)==1)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-5obLVYqXS9u"
   },
   "outputs": [],
   "source": [
    "unique_col = []\n",
    "for i in df_train.columns:\n",
    "    if np.unique(df_train[i]).shape[0]==1:\n",
    "        unique_col.append(i)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGM_VuudXS9y"
   },
   "outputs": [],
   "source": [
    "unique_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lv01TaxMXS91"
   },
   "outputs": [],
   "source": [
    "df_train.describe()[unique_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAVYlsadXS93"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop(unique_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LKVzBIbXS95"
   },
   "source": [
    "## 3) 資料前處理\n",
    "\n",
    "#### **特徵標準化**\n",
    "通常有兩種標準化的方法：\n",
    "- min max normalization：\n",
    "    - 會將特徵數據按比例縮放到 0 到 1 的區間，（或是 -1 到 1）。\n",
    "- standard deviation normalization：\n",
    "    - 會將所有特徵數據縮放成平均為 0、平方差為 1。\n",
    "    \n",
    "#### **特徵組合**\n",
    "特徵需要適當地增加和減少，以提升精確度並減少計算時間。\n",
    "- 增加特徵：特徵組合 (Feature Combination)、群聚編碼 (GroupBy Encoding)、產生合成樣本 (Oversampling)\n",
    "- 減少特徵：特徵篩選 (Feature Selection)、剔除一些樣本 (Undersampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0qpmm-a5XS99"
   },
   "source": [
    "<img src=\"https://drive.google.com/uc?export=download&id=10KIP1EWz3UUyoATe7GcNWeYm1nc7EXgU\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ey4l-nwXS9_"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5L-iTwBXS-B"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(df_input, train=True, sc=None):\n",
    "    # numeric feature standardization\n",
    "    if train:\n",
    "        sc = StandardScaler()\n",
    "#         sc = MinMaxScaler()\n",
    "        df = sc.fit_transform(df_input.iloc[:, 0:-1])\n",
    "    else:\n",
    "        df = sc.transform(df_input)\n",
    "    return df, sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvmldhncXS-D"
   },
   "outputs": [],
   "source": [
    "X, train_sc = data_preprocessing(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eToe3X-BXS-E"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fhySUf0XS-F"
   },
   "outputs": [],
   "source": [
    "train_sc.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iL1QmisbXS-G"
   },
   "outputs": [],
   "source": [
    "train_sc.var_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSLh8t8ZXS-I"
   },
   "source": [
    "## 3) One hot encoding\n",
    "對`Cover Type`輸出欄位的資料做 one-hot encoding，使用 Keras 提供的工具函式 to_categorical 將每筆資料的輸出值 y 轉換成一個向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ygx_KpfyXS-J"
   },
   "outputs": [],
   "source": [
    "y = df_train['Cover_Type'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2H0XuZ8XS-K"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e1Q39L5XS-L"
   },
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTdO2MRcXS-M"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHiQhI7MXS-N"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTj4B7vOXS-O"
   },
   "outputs": [],
   "source": [
    "np.unique(y, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7mLxLRXXS-P"
   },
   "source": [
    "## 4) 切割訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EZuojIAFXS-Q"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_valid , y_train , y_valid = train_test_split(X, y, test_size=0.3, random_state=17, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZn4UtPUXS-R"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y.argmax(-1), return_counts=True)\n",
    "plt.bar(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-pbw2hbXS-S"
   },
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train.argmax(-1), return_counts=True)\n",
    "plt.bar(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gW3oHFYXS-T"
   },
   "outputs": [],
   "source": [
    "print('訓練資料: ', X_train.shape, '\\t訓練目標: ', y_train.shape)\n",
    "print('驗證資料: ', X_valid.shape, '\\t驗證目標: ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUYYZAHfXS-U"
   },
   "source": [
    "## 5) 建立網路模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drdnLym0XS-V"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Sequential, callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrj7rtAcXS-Y"
   },
   "outputs": [],
   "source": [
    "# 此範例使用 Sequential API 搭建神經網路。\n",
    "def build_model(X):\n",
    "    tf.random.set_seed(17)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=X.shape[1:]))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(y_train.shape[1], Activation('softmax')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y7GVLf61XS-a"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = build_model(X_train)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WLSdcUKZXS-g"
   },
   "outputs": [],
   "source": [
    "# 編譯模型\n",
    "optim = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optim,   # w_new = w_old - learning_rate * gradient\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# rlp = callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',  # 是否進步的指標\n",
    "#     factor=0.1,  # 以 factor 的倍數調整 learning rate\n",
    "#     patience=5,  # 經過 patience 次沒有進步調整 learning rate\n",
    "#     verbose=2,\n",
    "#     mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKv1N6hfXS-l"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    shuffle=True)#, callbacks=[rlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_old = model.layers[0].trainable_weights[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_new = model.layers[0].trainable_weights[0].numpy()\n",
    "\n",
    "# (a_new-a_old).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi0FcnpgXS-m"
   },
   "source": [
    "## 6) 觀察訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-y9ViM0vXS-n"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J06zMLRwXS-o"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs_ = range(1,len(acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9agP1h_aXS-p"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_ , loss , label = 'training loss')\n",
    "plt.plot(epochs_ , val_loss , label = 'val los')\n",
    "plt.title('training and val loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_ , acc , label='train accuracy')\n",
    "plt.plot(epochs_ , val_acc , label = 'val accuracy')\n",
    "plt.title('train and val acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('acc')\n",
    "plt.ylim((0.5, 1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpGA8QspXS-p"
   },
   "source": [
    "## 觀察訓練集上的成效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-sGpb66XS-1"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_train, y_train, verbose=0)\n",
    "print(f'loss:{loss}, accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TA8CHUDJXS-3"
   },
   "source": [
    "## 觀察驗證集上的成效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0RzxTkwXS-4"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "label=np.argmax(y_valid,axis=1)\n",
    "pred =  np.argmax(model.predict(X_valid), axis=1)\n",
    "accuracy_score(label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1cs740qXS-7"
   },
   "outputs": [],
   "source": [
    "model.predict(X_valid)[:10].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ7k3B5vXS-8"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKz9ZbFAXS--"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(label, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gbyxexmXS-_"
   },
   "source": [
    "## 預測 test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhCnmr2MXS_B"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/Test.csv')\n",
    "df_test = df_test.drop(unique_col, axis=1)\n",
    "df_test = df_test.drop(labels=['Id'],axis=1)\n",
    "test, _ = data_preprocessing(df_test, train=False, sc=train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_3oqhoMXS_C"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSGClN39XS_E"
   },
   "outputs": [],
   "source": [
    "predict_class = np.argmax(pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bZupbBGYXS_G"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/Test.csv')\n",
    "ans = df_test[['Id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0nvAv74XS_G"
   },
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFexfSfzXS_H"
   },
   "outputs": [],
   "source": [
    "ans.loc[:, 'class'] = list(predict_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_BX8GcSXS_I"
   },
   "outputs": [],
   "source": [
    "ans.to_csv('ans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruyKdwMAXS_J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
